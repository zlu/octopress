<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Deployment | @zlu]]></title>
  <link href="http://www.zlu.me/blog/categories/deployment/atom.xml" rel="self"/>
  <link href="http://www.zlu.me/"/>
  <updated>2013-09-17T10:17:36+08:00</updated>
  <id>http://www.zlu.me/</id>
  <author>
    <name><![CDATA[Zhao Lu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rolling Deployment]]></title>
    <link href="http://www.zlu.me/blog/2012/11/07/rolling-deployment/"/>
    <updated>2012-11-07T20:30:00+08:00</updated>
    <id>http://www.zlu.me/blog/2012/11/07/rolling-deployment</id>
    <content type="html"><![CDATA[<p>It is common to deploy new code to production several times a week (or even a day) in an agile shop.  How to make deployment
less intrusive to end user has becoming a larger issue.  If you simply use <code>cap deploy production</code>, some web requests will
time out hence hamper consumer experience.  Heroku supports maintenance mode, which can be turned on before a deployment.
User will see a maintenance page instead of unresponsive web page.  This is ok but not ideal.</p>

<p>Martin Fowler wrote about <a href="http://martinfowler.com/bliki/BlueGreenDeployment.html">Blue Green Deployment</a>.  The canonical
form of this deployment strategy is to maintain two identical databases for each environment.  There is an issue of
dealing with missed transactions when deploying to one environment (stand-by) while the live environment is still taking
web requests.  There are a few ways to take care of this such as putting the live environment into read-only mode before the
cut-over.</p>

<p>For a small application (or a typical start-up scenario), having two database is a bit of over-kill and entails higher
operational costs.  With rolling deployment,  all the production web (application) servers share the same database.  To
reduce application downtime, only one web server will be taken out of the load balancer at a time.  This web server will then
be loaded with new code.  We can then run some quick automated tests (simple selenium tests for example) to ensure the build
is sane, against this web server.  If tests pass, we bring the node back into the load balancer.  We then repeat this process
for the next server.  If there are database changes that could potentially affect the state of the application and cause
inconsistency, then measure must be taken in the application to mitigate the problem through for example, back-fill.</p>

<h2>Setup</h2>

<p>A typical setup for a web app where multiple web servers (such as Unicorn) share the same database server.</p>

<pre>
                  |-> web server1 (red)   -|
load balancer --> |-> web server2 (blue)  -|---> database
                  |-> web server3 (green) -|
</pre>


<h2>Steps</h2>

<ul>
<li>Take the red web server out of load balancer</li>
<li>Deploy new code to red</li>
<li>Run deployment tests against red to ensure everything is sane</li>
<li>If tests pass, put red back to load balancer and continue to the next node, blue</li>
<li>If tests fail, roll back</li>
</ul>


<h2>Example</h2>

<p>In this example, I use Apache&rsquo;s <a href="http://httpd.apache.org/docs/2.2/mod/mod_proxy_balancer.html">mod_proxy_balancer</a>.
I use a typical Rails web server setup and <a href="https://github.com/capistrano/capistrano">Capistrano</a> for deployment.</p>

<p>{% codeblock In Rails' production.rb lang:ruby %}
role :app, &ldquo;server1.com&rdquo;, :group => :red
role :app, &ldquo;server2.com&rdquo;, :group=> :blue
role :app, &ldquo;server3.com&rdquo;, :group => :green
role :apache, &ldquo;loadbalancer.com&rdquo;, :no_release => true
{% endcodeblock %}</p>

<p>{% codeblock In Capistrano&rsquo;s deploy.rb lang:ruby %}
def manage_node(action, group)
  uri = URI.parse(&ldquo;<a href="http://#">http://#</a>{roles[:apache]}/balancer-manager&rdquo;)
  response_body = Net::HTTP.get_response(uri).body
  nonce = response_body.match(/nonce=(.*)\&ldquo;/)[1]
  node = find_servers(:roles => :app, :only => {:group => group.to_sym})[0]
  params = {:w => "<a href="http://#">http://#</a>{node}:8080&rdquo;, :b => stage, :nonce => nonce, :dw => action}
  uri.query = URI.encode_www_form(params)
  response = Net::HTTP.get_response(uri)
  response.code == &ldquo;200&rdquo;
end
{% endcodeblock %}</p>

<p>mod_proxy_balancer has a balancer-manager GUI.  Admin is able to enable and disable node (web server) via a form.
manage_node method essentially submit the form to the balancer-manager.</p>

<p>To take red node out of the load balancer, simply define a task such as:
<code>ruby
task :enable do
  manage_mode("Enable", group),
end
</code>
The value of group can be passed in as a command line option for Capistrano</p>

<h2>Other Considerations</h2>

<p>Why do I suggest running some basic tests as the acceptance criteria for rolling deployment?  I assume that the code
being deployed is well tested and passed CI/QA etc.  But there&rsquo;re all kinds of factors that can be different between test,
CI, and production environment.  Some library have different versions, VM images, or even the OS can be different.  I like
to use a Mac Mini for in-house CI (or Travis for open-source projects).  There&rsquo;s no guarantee that Travis or Mac Mini
can be kept up-to-date with production environment.  I could spin up a CI instance that replicates production but keeping
them in-sync still takes much effort.  There are also possibilities that integration test suites do not test views where
a simple route change could prevent user from successfully logging in.  By running a simple Selenium test to login and
perform one core function of the application, it gives me some level of assurance.</p>

<p>Capistrano supports deployment to a single server using HOSTS or HOSTFITLER command line options.  However, the load balancer
will keep sending requests to the server during deployment and server restart.</p>

<h2>Note</h2>

<p><a href="http://rdoc.info/github/capistrano/capistrano/master/Capistrano/Configuration/Servers">find_server API</a></p>
]]></content>
  </entry>
  
</feed>
